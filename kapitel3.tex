\chapter{Konzeptionierung}
\label{chap:konzeptionierung}
\ihead{Konzeptionierung}

\section{Evaluierung der Tools und Technologien}
\label{sec:evaluierung-technologien}

Für die Implementierung von \textbf{XL Fabric} wurden verschiedene Python-Bibliotheken und Frameworks evaluiert, um die bestmögliche Lösung für die Anforderungen des Projekts zu finden. Die Evaluierung konzentrierte sich auf zwei Hauptbereiche: Datenvalidierung und Excel-Verarbeitung.

\subsection{Datenvalidierungs-Frameworks}
Für die Datenvalidierung wurden Pydantic, Marshmallow sowie Cerberus betrachtet. Gewählt wurde \textbf{Pydantic V2}, da es moderne Typisierung und automatische Konvertierung bietet, in Benchmarks sehr performant ist, umfangreiche Validatoren mitbringt und präzise Fehlermeldungen sowie JSON-Schema-Generierung liefert \cite[vgl.][]{pydantic_welcome_2025}.

\subsection{Excel-Verarbeitungs-Bibliotheken}
Für den Excel-Import standen openpyxl, pandas+openpyxl und xlrd zur Wahl. Entscheidend war \textbf{pandas} mit \textbf{openpyxl}: DataFrames erlauben effiziente Transformationen, Multi-Sheet-Verarbeitung ist unkompliziert und die Bibliotheken sind breit etabliert \cite[vgl.][]{numfocus_inc_pandas_2029, eric_gazoni_openpyxl_2024}.

\section{Evaluierung der Alternativen: Nutzwertanalyse}

Zur Entscheidungsfindung wurde eine pragmatische Nutzwertbetrachtung durchgeführt. Bewertet wurden fünf Kriterien mit praxisnahen Gewichtungen. Die Skala der Einzelbewertungen reicht von 1 (schwach) bis 5 (sehr gut). Ausschlaggebend waren Typunterstützung, Performance, Validierungsumfang, Fehlertransparenz und Dokumentation.

\begin{table}[ht]
	\begin{center}
	\scriptsize
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
			\hline
			\multirow{2}{*}{Kriterien} & \multirow{2}{*}{Gewichtung} & \multicolumn{2}{c|}{\makecell{Pydantic}} & \multicolumn{2}{c|}{\makecell{Marshmallow}} & \multicolumn{2}{c|}{\makecell{Cerberus}} \\
			\cline{3-8}
			 &  & Bew. & Ges. & Bew. & Ges. & Bew. & Ges. \\
			\hline
			\makecell{Einarbeitungszeit} & 25\% & 4 & 1,00 & 4 & 1,00 & 3 & 0,75 \\
			\makecell{Performance} & 20\% & 5 & 1,00 & 3 & 0,60 & 3 & 0,60 \\
			\makecell{Flexibilität} & 25\% & 4 & 1,00 & 4 & 1,00 & 3 & 0,75 \\
			\makecell{Dokumentation} & 15\% & 5 & 0,75 & 4 & 0,60 & 3 & 0,45 \\
			\makecell{Community- \\ Unterstützung} & 15\% & 5 & 0,75 & 4 & 0,60 & 3 & 0,45 \\
			\hline
			GESAMT & 100\% & - & 4,50 & - & 3,80 & - & 3,00 \\
			\hline
	\end{tabular}
	\end{center}
	\caption{Nutzwertanalyse der Validierungsframeworks (Konzeption)}
	\label{tabelle:nutzwertanalyse_validierung_konzeption}
\end{table}

Das Ergebnis zeigt einen deutlichen Vorteil für Pydantic – insbesondere durch starke Performance (Rust-basiertes pydantic-core), enge Integration mit Python Type Hints und eine sehr gute Dokumentation. Marshmallow punktet mit ausgereifter Serialisierung und breiter Verbreitung, ist jedoch spürbar langsamer. Cerberus überzeugt durch einfache Schemata, erreicht jedoch weder die Typsicherheit noch die Ausdrucksstärke der anderen beiden Optionen.

\section{Projektordnerstruktur}
\label{sec:projektordnerstruktur}

Die Struktur von \textbf{XL Fabric} folgt einer klaren Trennung nach Verantwortlichkeiten: Im Hauptpaket \texttt{xl\_fabric/} liegen die Pydantic-Modelle getrennt nach Input (\texttt{models/xlsx/}) und Output (\texttt{models/aciconfig/}), die Konvertierungslogik (\texttt{converter/}), der Excel-Parser (\texttt{xls.py}), die \ac{CLI} (\texttt{cli.py}) und der \ac{YAML}-Export (\texttt{export.py}). Das Verzeichnis \texttt{files/} enthält die Arbeitsordner für Excel-Input und \ac{YAML}-Output, während unter \texttt{config/} die Logging- und Projektkonfiguration abgelegt ist. Tests befinden sich zentral unter \texttt{tests/}, Abhängigkeiten werden über \texttt{requirements.txt} verwaltet.

\section{Systemarchitektur}
\label{sec:systemarchitektur}

	\textbf{XL Fabric} folgt einer Pipeline-Architektur mit klar getrennten Verarbeitungsschritten. Die \ac{CLI} nimmt über den Befehl \texttt{generate} Eingabe- und Ausgabeverzeichnisse sowie das Flag \texttt{--terraform} für den Terraform-Export entgegen (ein vorbereitetes \texttt{--ansible} Flag existiert im Code, wurde jedoch nicht implementiert oder weiterentwickelt). Ein Parser auf Basis von pandas und openpyxl liest mehrblättrige Excel-Dateien ein, unterstützt dabei verschiedene Layouts (vertikal, horizontal, verschachtelt) und transformiert die Daten in Python-Dictionaries. Die erste Validierungsschicht nutzt Pydantic-Modelle unter \path{xl_fabric.models.xlsx}, um alle \ac{ACI}-Objekte wie Tenants, \ac{VRF}s, \ac{BD}s, \ac{EPG}s, Contracts, L3Outs, Domains und Interface Policies zu prüfen – dabei werden Pflichtfelder, Datentypen, Wertebereiche (\ac{VLAN}-IDs, \ac{IP}-Adressen) und Cross-References validiert. Die Klasse \texttt{XltoAciConfig} transformiert anschließend die validierten Daten in die Terraform-Modulstruktur, löst Referenzen auf und ergänzt Metadaten. Eine zweite Pydantic-Schicht unter \path{xl_fabric.models.aciconfig} prüft die Modulkonformität, Field-Aliase und Typkorrektheit, bevor der \texttt{AciConfigExporter} strukturierte \ac{YAML}-Dateien für Terraform erzeugt – aufgeteilt in Fabric-weite Konfigurationen (\ac{VLAN}-Pools, Domains, Interface Policies) und Tenant-spezifische Objekte (\ac{VRF}s, \ac{BD}s, \ac{EPG}s, Contracts). Ein zentrales Logging-System protokolliert alle Schritte mit Log-Leveln von DEBUG bis CRITICAL und liefert bei Fehlern detaillierte Positionsangaben mit Excel-Zeile und Spalte.

\section{Systemablauf}
\label{sec:systemablauf}

Um den Gesamtprozess und die Architektur von \textbf{XL Fabric} besser zu veranschaulichen, zeigt das folgende Ablaufdiagramm den Datenfluss vom Excel-Import bis zum YAML-Export. Abbildung~\ref{fig:ablaufdiagramm-kompakt} beschreibt die zentrale Verarbeitungskette in vereinfachter Form (das ausführliche Ablaufdiagramm mit allen Fehlerbehandlungen findet sich im Anhang, Abbildung~\ref{fig:ablaufdiagramm-detail}):

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{bilder/Vereinfachtes Ablaufdiagramm.png}
\caption{Vereinfachtes Ablaufdiagramm der Hauptverarbeitungsschritte}
\label{fig:ablaufdiagramm-kompakt}
\end{figure}

\subsection{Excel-Import und Parsing}

Der Prozess startet mit dem Einlesen der Excel-Dateien aus \texttt{files/input/}. \texttt{parse\_excelfile} lädt per openpyxl die Workbook-Struktur, pandas übernimmt die Datenmanipulation je Worksheet. Kopfzeilen werden erkannt, leere Zeilen und Spalten bereinigt, Datentypen automatisch interpretiert; mehrere Dateien können nacheinander verarbeitet und zusammengeführt werden.

\subsection{Input-Validierung mit Pydantic}

Nach dem erfolgreichen Parsing werden die Daten in Pydantic-Modelle überführt. Diese erste Validierungsschicht ist entscheidend für die Datenqualität.

\subsubsection{Validierungsbeispiel: Bridge Domain}

Eine Bridge Domain muss zwingende Felder wie \texttt{name}, \texttt{tenant} und \texttt{vrf} enthalten, Subnets als \ac{IP}-Interface akzeptieren und Parameter wie \texttt{unicast\_routing}, \texttt{l2\_unknown\_unicast} und \texttt{arp\_flooding} korrekt ausweisen. Pydantic prüft Datentypen, Pflichtfelder, erlaubte Werte und \ac{IP}-Gültigkeit und liefert bei Fehlern präzise, feldgenaue Meldungen mit erwarteten versus tatsächlichen Werten.

\subsection{Konvertierung und Transformation}

Die Klasse \texttt{XltoAciConfig} erstellt für jeden Excel-Eintrag passende \ac{ACI}-Objekte, löst Referenzen (z. B. \ac{EPG} → \ac{BD} → \ac{VRF} → Tenant), passt die Struktur an die Terraform-Module an, ergänzt erforderliche Metadaten und aggregiert zusammengehörige Informationen wie Subnets.

\subsection{Output-Validierung}

Die konvertierten Daten werden anschließend gegen Output-Modelle geprüft: Modulkompatibilität, Referenzen, Vollständigkeit und Konsistenz (z. B. \ac{VLAN}-IDs) werden sichergestellt.

\subsection{YAML-Export}

Im letzten Schritt entstehen strukturierte \ac{YAML}-Dateien, separat pro Objekt-Typ und gegliedert nach Fabric- bzw. Tenant-Kontext; Formatierung und optionale Ansible-Variablen sind berücksichtigt.

\section{Validierungskonzept mit Pydantic}
\label{sec:pydantic-modelle}

Die in diesem Kapitel beschriebenen Konzepte bauen auf den Entscheidungen aus Abschnitt~\ref{sec:evaluierung-technologien} auf. Die Pydantic-Modelle bilden das Herzstück der Validierung und sind in zwei Ebenen organisiert: Input-Modelle unter \path{xl_fabric.models.xlsx} orientieren sich an der Excel-Struktur und nutzen PascalCase-Feldnamen sowie primär String-Typen, da Excel-Daten zunächst als Text eingelesen werden – ein Beispiel ist das Modell \texttt{\ac{BD}} mit Pflichtfeldern wie \texttt{Name}, \texttt{Tenant} und \texttt{\ac{VRF}} sowie optionalen Feldern wie \texttt{Subnet} oder \texttt{L3Out}. Output-Modelle unter \path{xl_fabric.models.aciconfig} sind auf Terraform optimiert, verwenden snake\_case-Feldnamen und komplexe Typen wie \texttt{ipaddress.IPv4Interface} für \ac{IP}-Adressen oder \texttt{bool} statt Strings – so wird aus \texttt{ARPFlooding: str} im Input-Modell \texttt{arp\_flooding: bool} im Output-Modell. Pydantic konvertiert dabei automatisch Strings wie \texttt{"192.168.1.1/24"} in \texttt{IPv4Interface}-Objekte und erkennt ungültige \ac{IP}-Adressen (z.B. \texttt{192.168.1.256/24}) durch detaillierte Validierungsfehler. Verschachtelte Strukturen wie Subnets werden als eigenständige Sub-Modelle abgebildet, Union-Types erlauben flexible Eingaben (einzelne \ac{IP} oder Liste), und Container-Modelle auf Basis von \texttt{RootModel} fassen Collections in Dictionary-Form zusammen. Custom Validators prüfen Cross-References (z.B. ob eine referenzierte \ac{VRF} existiert), Wertebereiche (\ac{VLAN}-IDs 1-4094) und Konsistenzen – vollständige Beispiele finden sich im Anhang (Codebeispiele~\ref{code:bd_input_model}, \ref{code:bd_output_model}, \ref{code:custom_validator}).

% Evaluierungsdetails (Nutzwertanalyse) sind vollständig in Kapitel 2 verortet.

\section{Zweistufige Validierungsstrategie}
\label{sec:validierungsstrategie}

Das Kernkonzept von \textbf{XL Fabric} ist die zweistufige Validierung: Die erste Stufe prüft unmittelbar nach dem Excel-Import Struktur, Pflichtfelder, Basistypen, Formate (\ac{IP}-Adressen, \ac{VLAN}-IDs) und Referenzen – für jedes Sheet wird das entsprechende Pydantic-Modell instanziiert, wobei Pydantic automatisch gegen Typ-Definitionen validiert und Custom Validators zusätzliche Regeln prüfen. Bei Fehlern wird der Prozess sofort abgebrochen und Pydantic liefert detaillierte Meldungen mit Excel-Sheet, Zeile, Feld, Fehlertyp (z.B. \texttt{missing}, \texttt{type\_error}, \texttt{value\_error}) sowie erwartetem versus tatsächlichem Wert – ein typischer Fehler zeigt etwa \texttt{BDs -> 23 -> VRF: referenced VRF 'prod-vrf' not found in Tenant 'common'}. Die zweite Stufe erfolgt nach der Konvertierung und prüft Modulkonformität, Terraform-Hierarchie, finale Typkorrektheit (bool statt String, \ac{IP}-Objekte), Referenz-Integrität und Metadaten-Vollständigkeit – Fehler deuten hier auf Programmfehler in der Konvertierungslogik hin. Die Trennung bietet mehrere Vorteile: Frühe Fehlererkennung spart Rechenzeit, klare Unterscheidung zwischen Benutzer- und Programmfehler, Garantie Terraform-kompatibler Dateien, Wartbarkeit durch modulare Anpassungen und unabhängige Testbarkeit beider Stufen.

\section{Fehlerbehandlung und Logging}
\label{sec:fehlerbehandlung}

XL Fabric klassifiziert Fehler in fünf Kategorien: Parsing-Fehler bei korrupten Dateien, Input-Validierungsfehler als Benutzerfehler, Konvertierungs- und Output-Validierungsfehler als Programmfehler sowie Export-Fehler bei I/O-Problemen. Validierungsfehler werden strukturiert aufbereitet mit genauem Fehlerort (Sheet, Zeile, Spalte), Pydantic-Fehlertyp, Erwartung versus Realität und konkreten Korrekturhinweisen (siehe Anhang, Codebeispiel~\ref{code:error_handling}). Das Logging nutzt Standard-Level von DEBUG für detaillierte Entwicklungsinformationen über INFO für Statusmeldungen bis ERROR für Abbruchfehler und CRITICAL für Systemfehler – konfiguriert über \texttt{config/logging.json}.

\section{Zusammenfassung}

Die Konzeption von \textbf{XL Fabric} kombiniert eine modulare Architektur mit klarer Trennung von Parsing, Validierung, Konvertierung und Export, zweistufiger Validierung für Excel-Daten und Terraform-Strukturen, konsequenter Type-Safety durch Python Type Hints und Pydantic, mehrschichtigem Fehlerbehandlungssystem mit strukturierten Meldungen sowie leichter Erweiterbarkeit um neue \ac{ACI}-Objekte. Die automatische Typkonvertierung durch Pydantic, frühe Fehlererkennung, präzise Fehlermeldungen und die Pipeline-Architektur machen das Tool zu einer robusten Lösung für die Transformation Excel-basierter \ac{ACI}-Konfigurationen in Terraform-kompatibles \ac{YAML}.