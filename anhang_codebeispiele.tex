\clearpage
\ihead[]{Anhang: Codebeispiele}
\addcontentsline{toc}{section}{Anhang: Codebeispiele}
{\Large\bfseries Anhang: Codebeispiele}

\vspace{0.5em}
\begin{lstlisting}[language=Python, caption={Pydantic-Modell für Bridge Domain Input-Validierung}, label={code:bd_model}]
from typing import List, Optional
from pydantic import BaseModel


class BD(BaseModel):
    """Bridge Domain Model fuer Input-Validierung.
    
    Validiert alle Felder aus der Excel-Datei und stellt sicher,
    dass alle erforderlichen Parameter vorhanden und korrekt
    formatiert sind.
    """
    ARPFlooding: str
    AdvExternally: Optional[str]
    AdvHostRoutes: Optional[str]
    Description: Optional[str]
    L2UnknownUnicast: str
    MultiDestinationFlooding: str
    Name: str  # Pflichtfeld
    Shared: Optional[str]
    Subnet: Optional[str]  # Wird als IPv4Interface validiert
    Tenant: str  # Pflichtfeld, muss existierenden Tenant referenzieren
    UnicastRouting: Optional[str]
    VRF: str  # Pflichtfeld, muss existierende VRF referenzieren
    L3Out: Optional[str] = ''


class BDs(BaseModel):
    """Container fuer alle Bridge Domains."""
    BDs: List[BD]
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Click-basierte CLI-Hauptfunktion in cli.py}, label={code:cli_main}]
import click
from pathlib import Path
from xl_fabric.converter.xl_to_aciconfig import XltoAciConfig
from xl_fabric.export import AciConfigExporter
from xl_fabric.xls import parse_excelfile
from xl_fabric.utils.log_utils import get_module_logger

logger = get_module_logger(__name__)


@click.group()
def cli():
    """Initialize CLI Group."""
    pass


@cli.command()
@click.option('--inputdir', '-i', type=click.Path(exists=True, 
              path_type=Path), default='./files/input',
              help='Pfad zum Verzeichnis mit Excel-Dateien.')
@click.option('--outputdir', '-o', type=click.Path(exists=True, 
              path_type=Path), default='./files/output',
              help='Pfad zum Ausgabeverzeichnis.')
@click.option('--terraform', '-t', is_flag=True, 
              help='Terraform-Variablen generieren.')
@click.option('--ansible', '-a', is_flag=True, 
              help='Ansible-Variablen generieren (nicht implementiert).')
def generate(inputdir: Path, outputdir: Path, 
             ansible: bool, terraform: bool):
    """Generiere Terraform Variablen aus Excel-Dateien.
    
    Hinweis: Ansible-Funktionalitaet ist vorbereitet, 
    aber nicht implementiert.
    """
    
    file_list = list_files(inputdir)
    xls_content = None
    
    # Alle Excel-Dateien einlesen und zusammenfuehren
    for filepath in file_list:
        xls_content = import_xlsx(filepath, xls_content)
    
    # Konvertierung und Export (nur Terraform implementiert)
    if terraform:
        logger.info('Generiere Terraform-Variablen.')
        generate_terraform(xls_content, outputdir)
    if ansible:
        logger.warning('Ansible-Export ist nicht implementiert.')
        # generate_ansible(xls_content, outputdir)  # Nicht implementiert


def list_files(directory: Path, extensions: tuple = ('.xlsx',)) -> list:
    """Liste alle Excel-Dateien im Verzeichnis."""
    return [
        filepath for filepath in directory.iterdir()
        if filepath.is_file() 
        and filepath.suffix in extensions
        and not filepath.name.startswith('~')  # Temporaere Dateien ignorieren
    ]
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Excel-Parser mit pandas und openpyxl in xls.py}, label={code:excel_parser}]
import pandas as pd
from pathlib import Path
from openpyxl import load_workbook
from xl_fabric.utils.log_utils import get_module_logger

logger = get_module_logger(__name__)


def parse_excelfile(filepath: Path, concat_data: dict = None) -> dict:
    """Parse eine Excel-Datei und validiere die Daten.
    
    Args:
        filepath: Pfad zur Excel-Datei
        concat_data: Optional vorhandene Daten zum Zusammenfuehren
    
    Returns:
        dict: Validierte Excel-Daten als verschachteltes Dictionary
    """
    logger.info(f'Parse Excel-Datei: {filepath.name}')
    
    # Workbook laden mit openpyxl
    wb = load_workbook(filepath, data_only=True)
    excel_dict = concat_data if concat_data else {}
    
    # Jedes Worksheet verarbeiten
    for sheet_name in wb.sheetnames:
        logger.debug(f'Verarbeite Worksheet: {sheet_name}')
        
        # Spezielle Behandlung fuer ACI_Fabric und ACI_Management
        if sheet_name in ['ACI_Fabric', 'ACI_Management']:
            excel_dict[sheet_name] = import_pascal_design(wb, sheet_name)
            continue
        
        # Standard-Verarbeitung mit pandas
        df = pd.read_excel(filepath, sheet_name=sheet_name)
        
        # Datenbereinigung
        df = df.dropna(how='all')  # Leere Zeilen entfernen
        df = df.dropna(axis=1, how='all')  # Leere Spalten entfernen
        
        # In Dictionary konvertieren
        data = df.to_dict('records')
        
        # In excel_dict speichern
        if sheet_name in excel_dict:
            excel_dict[sheet_name].extend(data)
        else:
            excel_dict[sheet_name] = data
    
    logger.info(f'Excel-Datei erfolgreich geparst: {filepath.name}')
    return excel_dict


def import_pascal_design(wb, sheet_name: str) -> dict:
    """Spezielle Import-Funktion fuer Pascal-Design Worksheets."""
    ws = wb[sheet_name]
    data = {}
    
    for row in ws.iter_rows(min_row=2, values_only=True):
        if row[0]:  # Erste Spalte enthaelt den Key
            data[row[0]] = row[1]
    
    return data
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Bridge Domain Konvertierung in xl\_to\_aciconfig.py}, label={code:converter}]
from xl_fabric.models.aciconfig import BridgeDomains
from xl_fabric.utils.log_utils import get_module_logger

logger = get_module_logger(__name__)


def _convert_bridge_domains(self):
    """Konvertiere Bridge Domains von Excel zu Terraform-Struktur.
    
    Diese Methode transformiert die validierten Excel-Daten in die
    von Terraform erwartete Struktur fuer Bridge Domains.
    """
    logger.debug('Starte Bridge Domain Konvertierung.')
    bridge_domains = {}
    
    for bd in self.xl_data['BDs']:
        logger.debug(f'Verarbeite Bridge Domain: {bd["Name"]}')
        
        # Subnets verarbeiten und in Liste konvertieren
        subnets = []
        if bd.get('Subnet'):
            subnet_list = bd['Subnet'].split(',')
            for subnet_ip in subnet_list:
                subnet_dict = {
                    'ip': subnet_ip.strip(),
                    'description': bd.get('Description', ''),
                    'scope': ['public'] if bd.get('Shared') else ['private'],
                }
                subnets.append(subnet_dict)
        
        # L3Outs verarbeiten
        l3outs = []
        if bd.get('L3Out'):
            l3outs = [l3out.strip() for l3out in bd['L3Out'].split(',')]
        
        # ACI Config Objekt erstellen
        aci_bd = {
            'name': bd['Name'],
            'description': bd.get('Description', ''),
            'tenant': bd['Tenant'],
            'vrf': bd['VRF'],
            'subnets': subnets,
            'arp_flooding': bd.get('ARPFlooding', 'false').lower() == 'true',
            'unicast_routing': bd.get('UnicastRouting', 'true').lower() == 'true',
            'l2_unknown_unicast': bd.get('L2UnknownUnicast', 'proxy').lower(),
            'multi_destination_flooding': bd.get('MultiDestinationFlooding', 'bd-flood').lower(),
            'l3outs': l3outs,
        }
        
        # Key generieren (Name_Tenant)
        key = f"{aci_bd['name']}_{aci_bd['tenant']}"
        bridge_domains[key] = aci_bd
    
    logger.debug(f'Bridge Domain Konvertierung abgeschlossen. {len(bridge_domains)} BDs konvertiert.')
    
    # Output-Validierung durch Pydantic
    return BridgeDomains(bridge_domains)
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={YAML-Export-Funktion in export.py}, label={code:yaml_export}]
import yaml
import os
import shutil
from pathlib import Path
from xl_fabric.utils.log_utils import get_module_logger

logger = get_module_logger(__name__)


def represent_none(self, _):
    """Repraesentiere None als leeren String in YAML."""
    return self.represent_scalar('tag:yaml.org,2002:null', '')


yaml.add_representer(type(None), represent_none)


class AciConfigExporter:
    """Exportiere ACI Config Objekte als YAML-Dateien."""
    
    def __init__(self, base_output_dir, submodel_output_dirs):
        self.base_output_dir = Path(base_output_dir)
        self.submodel_output_dirs = {
            name: Path(output_dir) 
            for name, output_dir in submodel_output_dirs.items()
        }
    
    def export(self, pydantic_instance):
        """Hauptexport-Funktion."""
        logger.info('Starte YAML-Export.')
        
        # Altes Output-Verzeichnis bereinigen
        delete_files_and_dirs(self.base_output_dir)
        
        # Tenant-spezifische Daten exportieren
        self._export_tenants(pydantic_instance)
        
        # Fabric-weite Daten exportieren
        if hasattr(pydantic_instance, 'fabric'):
            self._export_systemsummary(pydantic_instance)
        
        # Generische Daten exportieren
        self._export_generic(pydantic_instance)
        
        logger.info('YAML-Export abgeschlossen.')
    
    def _export_tenants(self, pydantic_instance):
        """Exportiere Tenant-spezifische Objekte."""
        tenants = pydantic_instance.tenants.model_dump(by_alias=True)
        
        for _name, tenant in tenants.items():
            tenant_dir = self.base_output_dir / 'tenants' / tenant['name']
            tenant_dir.mkdir(parents=True, exist_ok=True)
            
            # Tenant-Definition
            self._export_to_yaml(
                tenant, 
                tenant_dir / f'{tenant["name"]}.yml'
            )
            
            logger.debug(f'Tenant {tenant["name"]} exportiert.')
    
    def _export_to_yaml(self, data, output_path):
        """Exportiere Daten als YAML-Datei."""
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(
                data, 
                f, 
                default_flow_style=False,
                allow_unicode=True,
                sort_keys=False
            )
        
        logger.debug(f'YAML-Datei erstellt: {output_path}')


def delete_files_and_dirs(dir_path):
    """Loesche alle Dateien und Verzeichnisse (ausser .gitkeep)."""
    for filename in os.listdir(dir_path):
        if filename == '.gitkeep':
            continue
        file_path = os.path.join(dir_path, filename)
        try:
            if os.path.isfile(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as err:
            logger.error(f'Fehler beim Loeschen von {file_path}: {err}')
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={ValidationError-Handling mit Pydantic}, label={code:error_handling}]
from pydantic import ValidationError
from xl_fabric.models.xlsx import BDs
from xl_fabric.utils.log_utils import get_module_logger

logger = get_module_logger(__name__)


def validate_bridge_domains(excel_data: dict) -> BDs:
    """Validiere Bridge Domain Daten aus Excel.
    
    Args:
        excel_data: Dictionary mit BD-Daten aus Excel
    
    Returns:
        BDs: Validiertes Pydantic-Objekt
    
    Raises:
        ValidationError: Bei Validierungsfehlern mit Details
    """
    try:
        # Pydantic-Validierung
        validated_bds = BDs(BDs=excel_data['BDs'])
        logger.info(f'{len(validated_bds.BDs)} Bridge Domains erfolgreich validiert.')
        return validated_bds
        
    except ValidationError as e:
        # Fehler formatieren und loggen
        logger.error('Validierungsfehler bei Bridge Domains:')
        
        for error in e.errors():
            # Fehlerposition extrahieren
            field_path = ' -> '.join(str(loc) for loc in error['loc'])
            error_msg = error['msg']
            error_type = error['type']
            
            # Excel-Zeile ermitteln (falls verfuegbar)
            if isinstance(error['loc'][0], int):
                excel_row = error['loc'][0] + 2  # +2 fuer Header + 0-Indexierung
                logger.error(
                    f'  Zeile {excel_row}, Feld "{field_path}": '
                    f'{error_msg} (Typ: {error_type})'
                )
            else:
                logger.error(
                    f'  Feld "{field_path}": {error_msg} (Typ: {error_type})'
                )
        
        # Benutzerfreundliche Fehlermeldung
        print('\n--- Validierungsfehler gefunden ---')
        print(f'Anzahl Fehler: {len(e.errors())}')
        print('Bitte korrigieren Sie die markierten Felder in der Excel-Datei.')
        print('Details siehe Log-Datei: logs/xlfabric.log\n')
        
        raise  # Exception weitergeben fuer CLI-Exit


# Beispielaufruf
if __name__ == '__main__':
    excel_data = {
        'BDs': [
            {
                'Name': 'BD-Web',
                'Tenant': 'Production',
                'VRF': 'VRF-Prod',
                'Subnet': '192.168.1.1/24',
                'ARPFlooding': 'true',
                'L2UnknownUnicast': 'flood',
                # ... weitere Felder
            }
        ]
    }
    
    try:
        validated = validate_bridge_domains(excel_data)
        print('Validierung erfolgreich!')
    except ValidationError:
        print('Validierung fehlgeschlagen. Siehe Fehler oben.')
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Zentrale Logger-Konfiguration in log\_utils.py}, label={code:logger_config}]
import logging


def get_module_logger(module_name):
    logger = logging.getLogger(module_name)
    logger.setLevel(logging.DEBUG)
    
    # Console Handler
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # File Handler
    file_handler = logging.FileHandler('logs/xlfabric.log')
    file_handler.setLevel(logging.DEBUG)
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    console_handler.setFormatter(formatter)
    file_handler.setFormatter(formatter)
    
    logger.addHandler(console_handler)
    logger.addHandler(file_handler)
    
    return logger
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Bridge Domain Output-Modell in models/aciconfig/bridge\_domains.py}, label={code:bd_output_model}]
import ipaddress
from typing import Dict, List, Optional, Union
from pydantic import BaseModel, RootModel


class Subnet(BaseModel):
    """Subnet-Modell fuer Output-Validierung.
    
    Nutzt komplexe Python-Typen fuer strenge Validierung.
    """
    ip: Optional[Union[ipaddress.IPv4Interface, 
                       List[ipaddress.IPv4Interface]]]
    description: str
    shared: Optional[bool]  # Boolean statt String!
    public: Optional[bool]


class BridgeDomain(BaseModel):
    """Bridge Domain Output-Modell fuer Terraform.
    
    Dieses Modell repraesentiert die finale Struktur,
    wie sie von Terraform-Modulen erwartet wird.
    """
    name: str  # Pflichtfeld
    description: Optional[str] = ''
    alias: Optional[str] = ''
    tenant: str  # Referenz zu Tenant
    vrf: str  # Referenz zu VRF
    subnets: List[Subnet]  # Liste von Subnet-Objekten
    adv_host_routes: Optional[bool] = False
    arp_flooding: bool = True  # Boolean mit Default
    l2_unknown_unicast: str  # Enum: 'proxy' oder 'flood'
    multi_destination_flooding: str  # Enum: 'bd-flood', 'drop', etc.
    unicast_routing: bool = True
    l3outs: Optional[List[str]] = []  # Liste von L3Out-Namen


class BridgeDomains(RootModel):
    """Container fuer alle Bridge Domains als Dictionary.
    
    Die Dictionary-Struktur mit Keys ist erforderlich fuer
    die Terraform-Module (NaC-Format).
    """
    root: Dict[str, BridgeDomain]
    
    def __iter__(self):
        """Ermoeglicht Iteration ueber Bridge Domains."""
        return iter(self.root)
    
    def __getitem__(self, item):
        """Ermoeglicht Dictionary-artigen Zugriff."""
        return self.root[item]
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Custom Validator fuer Referenzpruefung}, label={code:custom_validator}]
from pydantic import BaseModel, field_validator, ValidationError
from typing import List


class EPG(BaseModel):
    """Endpoint Group mit Cross-Reference-Validierung."""
    name: str
    tenant: str
    application_profile: str
    bridge_domain: str  # Muss existierende BD referenzieren
    
    @field_validator('bridge_domain')
    @classmethod
    def validate_bd_reference(cls, v, info):
        """Pruefe, ob referenzierte Bridge Domain existiert.
        
        Args:
            v: Wert des bridge_domain-Feldes
            info: ValidationInfo mit Kontext
        
        Returns:
            str: Validierter Bridge Domain Name
        
        Raises:
            ValueError: Wenn Bridge Domain nicht existiert
        """
        # Verfuegbare BDs aus Kontext holen (muss vorher gesetzt werden)
        available_bds = info.context.get('available_bridge_domains', [])
        
        if v not in available_bds:
            raise ValueError(
                f'Bridge Domain "{v}" nicht gefunden. '
                f'Verfuegbare BDs: {", ".join(available_bds)}'
            )
        
        return v


# Verwendungsbeispiel
if __name__ == '__main__':
    # Verfuegbare Bridge Domains definieren
    available_bds = ['BD-Web', 'BD-App', 'BD-DB']
    
    # Kontext fuer Validierung erstellen
    context = {'available_bridge_domains': available_bds}
    
    try:
        # EPG mit gueltiger BD-Referenz
        epg_valid = EPG.model_validate(
            {
                'name': 'EPG-WebServers',
                'tenant': 'Production',
                'application_profile': 'AP-WebApp',
                'bridge_domain': 'BD-Web'  # OK, existiert
            },
            context=context
        )
        print(f'EPG validiert: {epg_valid.name}')
        
    except ValidationError as e:
        print(f'Validierungsfehler: {e}')
    
    try:
        # EPG mit ungültiger BD-Referenz
        epg_invalid = EPG.model_validate(
            {
                'name': 'EPG-Unknown',
                'tenant': 'Production',
                'application_profile': 'AP-WebApp',
                'bridge_domain': 'BD-NonExistent'  # FEHLER!
            },
            context=context
        )
        
    except ValidationError as e:
        print(f'Erwarteter Fehler: {e}')
        # Output:
        # Bridge Domain "BD-NonExistent" nicht gefunden.
        # Verfuegbare BDs: BD-Web, BD-App, BD-DB
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Bridge Domain Input-Modell (Excel-Struktur) in models/xlsx/bds.py}, label={code:bd_input_model}]
from typing import List, Optional
from pydantic import BaseModel


class BD(BaseModel):
    """Bridge Domain Input-Modell fuer Excel-Validierung.
    
    Feldnamen entsprechen exakt den Excel-Spaltennamen.
    Alle Werte sind initial Strings, da Excel keine
    strikten Datentypen hat.
    """
    # Pflichtfelder (ohne Optional)
    Name: str  # Spalte "Name" in Excel
    Tenant: str  # Spalte "Tenant" in Excel
    VRF: str  # Spalte "VRF" in Excel
    ARPFlooding: str  # "true" oder "false" als String
    L2UnknownUnicast: str  # "proxy" oder "flood"
    MultiDestinationFlooding: str  # "bd-flood", "drop", etc.
    
    # Optionale Felder
    Description: Optional[str] = None
    UnicastRouting: Optional[str] = 'true'  # Default-Wert
    AdvHostRoutes: Optional[str] = None
    AdvExternally: Optional[str] = None
    Shared: Optional[str] = None
    Subnet: Optional[str] = None  # Komma-separierte Liste
    L3Out: Optional[str] = ''  # Komma-separierte Liste


class BDs(BaseModel):
    """Container fuer alle Bridge Domains aus Excel.
    
    Excel-Sheet "BDs" wird in diese Struktur geparst.
    """
    BDs: List[BD]
    
    def __len__(self):
        """Anzahl der Bridge Domains."""
        return len(self.BDs)
    
    def __iter__(self):
        """Iteration ueber Bridge Domains."""
        return iter(self.BDs)


# Verwendungsbeispiel
if __name__ == '__main__':
    # Simulierte Excel-Daten (als Dictionary nach Parsing)
    excel_data = {
        'BDs': [
            {
                'Name': 'BD-Web',
                'Description': 'Web Tier Bridge Domain',
                'Tenant': 'Production',
                'VRF': 'VRF-Prod',
                'Subnet': '192.168.10.1/24, 192.168.11.1/24',
                'ARPFlooding': 'true',
                'L2UnknownUnicast': 'proxy',
                'MultiDestinationFlooding': 'bd-flood',
                'UnicastRouting': 'true',
                'Shared': 'false',
                'L3Out': 'L3Out-Internet'
            },
            {
                'Name': 'BD-App',
                'Description': 'Application Tier',
                'Tenant': 'Production',
                'VRF': 'VRF-Prod',
                'Subnet': '10.0.20.1/24',
                'ARPFlooding': 'false',
                'L2UnknownUnicast': 'flood',
                'MultiDestinationFlooding': 'bd-flood',
                'UnicastRouting': 'true',
            }
        ]
    }
    
    # Validierung mit Pydantic
    try:
        validated_bds = BDs(**excel_data)
        print(f'Validierung erfolgreich: {len(validated_bds)} BDs')
        
        for bd in validated_bds:
            print(f'  - {bd.Name} (Tenant: {bd.Tenant}, VRF: {bd.VRF})')
            
    except ValidationError as e:
        print(f'Validierungsfehler: {e}')
\end{lstlisting}